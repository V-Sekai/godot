#!/usr/bin/env python
from misc.utility.scons_hints import *

Import("env")
Import("env_modules")

# Add include paths to global env so tests can access them
# Tests are compiled via tests/SCsub which uses env, not env_modules
# Note: LiteRT sources use #include "litert/c/..." so we need #thirdparty/litert (parent of litert/)
env.Prepend(CPPPATH=[
    "modules/litert",  # For module wrapper classes
    "#thirdparty/litert",  # For litert/c/ includes (allows litert/c/litert_common.h -> thirdparty/litert/litert/c/litert_common.h)
    "#thirdparty/flatbuffers/include",  # For flatbuffers headers (needed by tests)
    "#thirdparty/tensorflow-lite/tensorflow/lite",  # For tflite headers (needed by tests)
    "#thirdparty/tensorflow-lite/tensorflow",  # For tflite/schema includes
    "#thirdparty/litert/tflite",  # For tflite/converter/schema/mutable/ includes (needed by tests)
    "#thirdparty/litert/tflite/tensorflow/lite",  # Alternative path for tflite includes
])

env_litrt = env_modules.Clone()
# env_modules inherits from env, so it should have the paths above
# But ensure env_litrt also has them explicitly for thirdparty sources
# Note: LiteRT sources use #include "litert/c/..." so we need #thirdparty/litert (parent of litert/)
env_litrt.Prepend(CPPPATH=[
    "modules/litert",  # For module wrapper classes
    "#thirdparty/litert",  # For litert/c/ includes (allows litert/c/litert_common.h -> thirdparty/litert/litert/c/litert_common.h)
])

# Thirdparty source files - build litert static library

thirdparty_obj = []

thirdparty_dir = "#thirdparty/litert/litert/"

# C API sources
c_api_sources = [
    "c/litert_common.cc",
    "c/litert_compiled_model.cc",
    "c/litert_environment.cc",
    "c/litert_environment_options.cc",
    "c/litert_event.cc",
    "c/litert_layout.cc",
    "c/litert_metrics.cc",
    "c/litert_model.cc",
    "c/litert_op_options.cc",
    "c/litert_opaque_options.cc",
    "c/litert_options.cc",
    "c/litert_profiler.cc",
    "c/litert_rewriter.cc",
    "c/litert_tensor_buffer.cc",
    "c/litert_tensor_buffer_requirements.cc",
    "c/internal/litert_accelerator.cc",
    "c/internal/litert_accelerator_registration.cc",
    "c/internal/litert_delegate_wrapper.cc",
    "c/internal/litert_logging.cc",
    "c/internal/litert_tensor_buffer_registry.cc",
]

# Options sources
options_sources = [
    "c/options/litert_compiler_options.cc",
    "c/options/litert_cpu_options.cc",
    "c/options/litert_darwinn_runtime_options.cc",
    "c/options/litert_google_tensor_options.cc",
    "c/options/litert_gpu_options.cc",
    "c/options/litert_intel_openvino_options.cc",
    "c/options/litert_mediatek_options.cc",
    "c/options/litert_qualcomm_options.cc",
    "c/options/litert_runtime_options.cc",
    "c/options/litert_webnn_options.cc",
]

# Runtime sources
runtime_sources = [
    "runtime/accelerator_registry.cc",
    "runtime/accelerators/auto_registration.cc",
    "runtime/accelerators/dispatch/dispatch_accelerator.cc",
    "runtime/accelerators/xnnpack/xnnpack_accelerator.cc",
    "runtime/compiled_model.cc",
    "runtime/custom_buffer.cc",
    "runtime/custom_op_dispatcher.cc",
    "runtime/dispatch/dispatch_delegate.cc",
    "runtime/dispatch/dispatch_delegate_kernel.cc",
    "runtime/dispatch/dispatch_opaque_options.cc",
    "runtime/dispatch/litert_dispatch.cc",
    "runtime/event.cc",
    "runtime/external_litert_buffer_context.cc",
    "runtime/profiler.cc",
    "runtime/tensor_buffer.cc",
    "runtime/tensor_buffer_registry.cc",
    "runtime/tensor_buffer_requirements.cc",
    "runtime/tfl_utils.cc",
]

# Core sources
core_sources = [
    "core/build_stamp.cc",
    "core/buffer_error_reporter.cc",
    "core/error_reporter.cc",
    "core/dispatch_op_schema.cc",
    "core/environment.cc",
    "core/environment_options.cc",
    "core/filesystem.cc",
    "core/util/flatbuffer_tools.cc",
    "core/util/tensor_type_util.cc",
    "core/model/model.cc",
    "core/model/model_buffer.cc",
    "core/model/model_load.cc",
    # "core/model/model_serialize.cc",  # Requires tflite/schema/mutable/schema_generated.h which isn't available
    "core/model/flatbuffer_to_litert.cc",
    "core/model/litert_to_flatbuffer.cc",
    "core/model/graph_validation.cc",
    "core/cache/compilation_cache.cc",
]

# Platform-specific sources
if env["platform"] == "windows":
    core_sources.append("core/dynamic_loading_windows.cc")
else:
    core_sources.append("core/dynamic_loading.cc")

# Platform-specific GPU sources (enabled for GPU support)
# gpu_environment.cc is always needed for GPU support
runtime_sources.append("runtime/gpu_environment.cc")

# Metal support removed - WebGPU-only backend strategy

# Combine all sources
litert_sources = c_api_sources + options_sources + runtime_sources + core_sources
litert_sources = [thirdparty_dir + file for file in litert_sources]

# Add include paths
# Note: "#thirdparty/litert" is already added above, so litert/c/ includes work
env_litrt.Prepend(
    CPPPATH=[
        "#thirdparty/litert/litert/build_common/generated",  # For build_config.h (actual location)
        "#thirdparty/litert/litert",  # Direct path for litert/build_common/build_config.h includes
        thirdparty_dir + "build_common/generated",  # For build_config.h (alternative path)
        thirdparty_dir + "c",
        thirdparty_dir + "c/internal",
        thirdparty_dir + "c/options",
        thirdparty_dir + "runtime",
        thirdparty_dir + "runtime/accelerators",
        thirdparty_dir + "runtime/accelerators/dispatch",
        thirdparty_dir + "runtime/accelerators/xnnpack",
        thirdparty_dir + "runtime/dispatch",
        thirdparty_dir + "core",
        thirdparty_dir + "core/model",
        thirdparty_dir + "core/cache",
        thirdparty_dir + "core/util",
        "#thirdparty/litert/",
        # Dependency include paths
        "#thirdparty/abseil-cpp",  # For absl:: headers
        "#thirdparty/flatbuffers/include",  # For flatbuffers:: headers
        "#thirdparty/xnnpack/include",  # For xnnpack headers
        "#thirdparty/pthreadpool/include",  # For pthreadpool headers
        "#thirdparty/tensorflow-lite/tensorflow/lite",  # For tflite:: headers (from git subrepo)
        "#thirdparty/tensorflow-lite/tensorflow",  # For tflite/schema/ includes
        "#thirdparty/litert/tflite",  # LiteRT's bundled tflite (if still needed)
        "#thirdparty/litert/tflite/tensorflow/lite",  # For tflite/schema/mutable/ includes
    ]
)

# Add compile definitions
env_litrt.Append(
    CPPDEFINES=[
        "LITERT_COMPILE_LIBRARY",
        "LITERT_DISABLE_OPENCL_SUPPORT",  # Disable OpenCL support (not needed for basic functionality)
    ]
)

# Platform-specific compile definitions
if env["platform"] == "windows":
    # Windows-specific: disable MMAP for TFLite
    env_litrt.Append(
        CPPDEFINES=[
            "TFLITE_DISABLE_MMAP",
        ]
    )
else:
    # Unix-like platforms: enable MMAP
    env_litrt.Append(
        CPPDEFINES=[
            "TFLITE_ENABLE_MMAP",
        ]
    )

# Create thirdparty environment with warnings disabled
# env_litrt already has the include paths from above, including "#thirdparty/litert"
# This allows litert/c/litert_common.h to resolve to thirdparty/litert/litert/c/litert_common.h
env_thirdparty = env_litrt.Clone()
env_thirdparty.disable_warnings()
# LiteRT requires C++20 for designated initializers
if env["platform"] == "windows":
    env_thirdparty.Append(CXXFLAGS=["/std:c++20"])
else:
    env_thirdparty.Append(CXXFLAGS=["-std=c++20"])

# Build thirdparty sources
env_thirdparty.add_source_files(thirdparty_obj, litert_sources)

env.modules_sources += thirdparty_obj

# Godot source files (wrapper classes)

module_obj = []

env_litrt.add_source_files(module_obj, "*.cpp")
env.modules_sources += module_obj

# Needed to force rebuilding the module files when the thirdparty library is updated.
env.Depends(module_obj, thirdparty_obj)

# Test files (doctest)
# Note: Tests are compiled via tests/test_main.cpp which includes module test headers
# The test files need access to litert headers, so ensure env.modules_env includes our paths
if env["tests"]:
    env_litrt.Append(CPPDEFINES=["TESTS_ENABLED"])
    # Add test files to module_obj - they'll be included via test_main.cpp
    # The include paths are already set in env_litrt above
    if env["platform"] in ["windows", "macos", "linux", "linuxbsd", "android"]:
        env_litrt.Append(CPPDEFINES=["DOCTEST_CONFIG_NO_EXCEPTIONS_BUT_WITH_ALL_ASSERTS"])

# Build dependency libraries
# Note: These are complex libraries. For now, we include their source files.
# A full production build may require building these as separate static libraries.

# pthreadpool (simple - only 8 source files)
if True:  # Always build pthreadpool
    pthreadpool_dir = "#thirdparty/pthreadpool/"
    pthreadpool_sources = [
        "src/legacy-api.c",
        "src/memory.c",
        "src/shim.c",
        "src/portable-api.c",
    ]

    # Platform-specific sources
    if env["platform"] == "windows":
        pthreadpool_sources.append("src/windows.c")
    else:
        pthreadpool_sources.append("src/pthreads.c")
        # Add GCD for macOS/iOS
        if env["platform"] in ["macos", "ios"]:
            pthreadpool_sources.append("src/gcd.c")
        # Add fastpath for x86/x86_64
        # Note: This would need platform detection, for now include it
        if env["platform"] not in ["windows"]:
            pthreadpool_sources.append("src/fastpath.c")

    pthreadpool_sources = [pthreadpool_dir + file for file in pthreadpool_sources]

    env_pthreadpool = env_thirdparty.Clone()
    env_pthreadpool.Prepend(CPPPATH=[pthreadpool_dir + "include"])
    # C files are automatically compiled with CC compiler
    env_pthreadpool.add_source_files(thirdparty_obj, pthreadpool_sources)

# FlatBuffers library (only 4 source files needed - most is header-only)
if True:  # Always build flatbuffers
    flatbuffers_dir = "#thirdparty/flatbuffers/"
    flatbuffers_sources = [
        "src/idl_parser.cpp",
        "src/idl_gen_text.cpp",
        "src/reflection.cpp",
        "src/util.cpp",
    ]
    flatbuffers_sources = [flatbuffers_dir + file for file in flatbuffers_sources]

    env_flatbuffers = env_thirdparty.Clone()
    env_flatbuffers.Prepend(CPPPATH=[flatbuffers_dir + "include"])
    env_flatbuffers.add_source_files(thirdparty_obj, flatbuffers_sources)

# Abseil (complex - 455 .cc files, many transitive dependencies)
# NOTE: This is a minimal setup. Abseil has complex internal dependencies.
# Full production build would require building ~50-100 source files across multiple components.
# Components needed: status, statusor, strings (str_cat, str_format), span (header-only),
#                    flat_hash_map, plus base dependencies (config, core_headers, etc.)
if True:  # Build Abseil (minimal components)
    abseil_dir = "#thirdparty/abseil-cpp/"

    # Core base components (minimal - many are header-only)
    abseil_base_sources = [
        # Base components needed by others
        "absl/base/internal/raw_logging.cc",
        "absl/base/internal/strerror.cc",
        "absl/base/internal/throw_delegate.cc",
        # Additional base dependencies
        "absl/base/internal/low_level_alloc.cc",
        "absl/base/internal/spinlock.cc",
        "absl/base/internal/spinlock_wait.cc",
        "absl/base/internal/cycleclock.cc",
        "absl/base/internal/unscaledcycleclock.cc",
        "absl/base/internal/sysinfo.cc",
        "absl/base/internal/thread_identity.cc",
    ]

    # Status components (from BUILD.bazel: absl::status)
    abseil_status_sources = [
        "absl/status/status.cc",
        "absl/status/statusor.cc",
        "absl/status/internal/status_internal.cc",
        "absl/status/status_payload_printer.cc",
    ]

    # Strings components (from BUILD.bazel: absl::strings)
    abseil_strings_sources = [
        "absl/strings/str_cat.cc",
        "absl/strings/str_format.cc",
        "absl/strings/string_view.cc",  # May be needed
        # "absl/strings/internal/str_format_internal.cc",  # File not found - may not be needed
        "absl/strings/internal/stringify_sink.cc",
        "absl/strings/internal/charconv_bigint.cc",
        "absl/strings/internal/charconv_parse.cc",
        "absl/strings/internal/memutil.cc",
        "absl/strings/numbers.cc",
    ]

    # Container components (from BUILD.bazel: absl::container::flat_hash_map)
    abseil_container_sources = [
        "absl/container/internal/raw_hash_set.cc",
        "absl/container/internal/hashtablez_sampler.cc",
    ]

    # Combine all Abseil sources
    abseil_sources = abseil_base_sources + abseil_status_sources + abseil_strings_sources + abseil_container_sources
    abseil_sources = [abseil_dir + file for file in abseil_sources]

    # Note: This is incomplete - Abseil has many more transitive dependencies
    # (base::config, base::core_headers, memory, algorithm, etc.)
    # Full build would require ~50-100 source files total
    env_abseil = env_thirdparty.Clone()
    env_abseil.Prepend(CPPPATH=[abseil_dir])
    env_abseil.add_source_files(thirdparty_obj, abseil_sources)

# XNNPACK (extremely large - 8249 .c files) - OPTIONAL/SKIPPED
# NOTE: XNNPACK is only for CPU acceleration, not required for basic functionality
# TFLite can run without XNNPACK (slower but functional)
# For scrappiest approach: Skip XNNPACK entirely
# XNNPACK include paths are already added above for headers (won't break if unused)
# If XNNPACK is needed later, can be added as pre-built library or selective build

# TensorFlow Lite - Pre-built library (Scrappiest approach)
# NOTE: Build TFLite separately with CMake, then SCons will find it automatically
# Steps to build:
#   cd thirdparty/tensorflow-lite
#   mkdir build && cd build
#   cmake ../tensorflow/lite -DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=OFF -DTFLITE_ENABLE_GPU=OFF -DTFLITE_ENABLE_XNNPACK=OFF
#   cmake --build . -j$(nproc) --target tensorflow-lite
# SCons will automatically find libtensorflow-lite.a in the build directory
if True:  # Link pre-built TFLite library
    import os

    # Check multiple possible locations for the library
    tflite_build_dir = "#thirdparty/tensorflow-lite/build/"
    
    # Determine library extension based on platform
    if env["platform"] == "windows":
        lib_ext = ".lib"
        lib_name = "tensorflow-lite"
    else:
        lib_ext = ".a"
        lib_name = "libtensorflow-lite"
    
    tflite_lib_paths = [
        tflite_build_dir + lib_name + lib_ext,
        tflite_build_dir + "tensorflow/lite/" + lib_name + lib_ext,
        # Windows-specific paths
        tflite_build_dir + "Release/" + lib_name + lib_ext,
        tflite_build_dir + "tensorflow/lite/Release/" + lib_name + lib_ext,
        # Also check Unix-style .a for cross-platform builds
        tflite_build_dir + "libtensorflow-lite.a",
        tflite_build_dir + "tensorflow/lite/libtensorflow-lite.a",
    ]

    # Find the library
    tflite_lib_found = None
    for lib_path in tflite_lib_paths:
        if os.path.exists(lib_path):
            tflite_lib_found = lib_path
            break

    if tflite_lib_found:
        # Add the directory containing the library to LIBPATH
        tflite_lib_dir = os.path.dirname(tflite_lib_found)
        env_litrt.Append(LIBPATH=[tflite_lib_dir])
        # SCons will automatically add the correct extension based on platform
        env_litrt.Append(LIBS=["tensorflow-lite"])
    else:
        # Library not found - will need to build it separately
        # This is expected if TFLite hasn't been built yet
        pass

# Metal framework linking removed - WebGPU-only backend strategy

# NOTE: Dependency linking requirements
# LiteRT requires the following dependencies to be built and linked:
#
# Status (Scrappiest Approach):
# - ✅ pthreadpool: Built from source (8 files, simple)
# - ✅ FlatBuffers: Built from source (4 library files - most is header-only)
# - ✅ Abseil: Minimal build complete (~25 source files) - includes base, status, strings, container components
# - ⏭️ XNNPACK: SKIPPED (optional acceleration - TFLite works without it)
# - ⚠️ TensorFlow Lite: Pre-built library approach - build separately with CMake, link libtensorflow-lite.a
#
# These dependencies are currently included as git subrepos in thirdparty/:
# - thirdparty/abseil-cpp (git subrepo)
# - thirdparty/flatbuffers (git subrepo)
# - thirdparty/xnnpack (git subrepo)
# - thirdparty/pthreadpool (git subrepo) ✅ Building from source
# - thirdparty/tensorflow-lite (git subrepo - full TensorFlow repo)
# - thirdparty/litert/tflite (LiteRT's bundled TensorFlow Lite sources, if used)
#
# Next steps for scrappiest integration (to get matmul working):
# 1. ✅ Build FlatBuffers library - DONE (4 source files)
# 2. ✅ Build pthreadpool - DONE (8 source files)
# 3. ✅ Complete Abseil minimal build - DONE (~25 source files)
#    - Includes: base (low_level_alloc, spinlock, sysinfo, etc.), status, strings, container
# 4. ⏭️ XNNPACK - SKIPPED (optional, not needed for basic functionality)
# 5. ⚠️ Build TensorFlow Lite separately - TODO
#    - Steps: cd thirdparty/tensorflow-lite && mkdir build && cd build
#    - Run: cmake ../tensorflow/lite -DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=OFF -DTFLITE_ENABLE_XNNPACK=OFF
#    - Build: cmake --build . -j$(nproc) --target tensorflow-lite
# 6. ✅ Link pre-built TFLite library - SETUP DONE (SCsub will find library in build directory)
#
# Current state: pthreadpool, flatbuffers, and Abseil are fully built from source.
# XNNPACK is skipped (optional). TFLite linking is set up - SCons will find libtensorflow-lite.a
# in thirdparty/tensorflow-lite/build/ automatically when it exists.
